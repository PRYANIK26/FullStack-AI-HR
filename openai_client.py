import openai
import time
import threading
import logging
from datetime import datetime
from typing import List, Dict, Callable, Generator
from config import Config

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s.%(msecs)03d [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class OpenAIClient:
    def __init__(self):
        self.client = openai.OpenAI(api_key=Config.OPENAI_API_KEY)
        self.model = Config.OPENAI_MODEL
        
    def get_response_sync(self, messages: List[Dict[str, str]]) -> str:
        """Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ - Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ ÑÑ€Ð°Ð·Ñƒ"""
        request_id = int(time.time() * 1000000) % 1000000
        
        print(f"ðŸš€ [REQ-{request_id}] ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº OpenAI")
        start_time = time.time()
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
            )
            
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            content = response.choices[0].message.content.strip()
            
            print(f"âœ… [REQ-{request_id}] ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ Ð¾Ñ‚Ð²ÐµÑ‚ Ð·Ð° {response_time:.0f}Ð¼Ñ (Ð´Ð»Ð¸Ð½Ð°: {len(content)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)")
            
            return content
            
        except Exception as e:
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            logger.error(f"âŒ [REQ-{request_id}] ÐžÑˆÐ¸Ð±ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· {response_time:.0f}Ð¼Ñ: {e}")
            raise Exception(f"OpenAI API Error: {e}")
    
    def get_response_stream(self, messages: List[Dict[str, str]], 
                          sentence_callback: Callable[[str], None]) -> str:
        """
        ÐŸÐ¾Ñ‚Ð¾ÐºÐ¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ - ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‡Ð°Ð½ÐºÐ¸ Ð² Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ñ… Ñ‡ÐµÑ€ÐµÐ· callback
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
        """
        request_id = int(time.time() * 1000000) % 1000000
        
        logger.info(f"ðŸŒŠ [STREAM-{request_id}] ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº OpenAI")
        start_time = time.time()
        first_chunk_time = None
        chunk_count = 0
        
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                reasoning_effort="minimal",
                stream=True
            )
            
            full_response = ""
            current_sentence = ""
            sentence_count = 0
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    current_time = time.time()
                    
                    if first_chunk_time is None:
                        first_chunk_time = current_time
                        time_to_first_chunk = (first_chunk_time - start_time) * 1000
                        logger.info(f"âš¡ [STREAM-{request_id}] ÐŸÐµÑ€Ð²Ñ‹Ð¹ Ñ‡Ð°Ð½Ðº Ñ‡ÐµÑ€ÐµÐ· {time_to_first_chunk:.0f}Ð¼Ñ")
                    
                    chunk_text = chunk.choices[0].delta.content
                    full_response += chunk_text
                    current_sentence += chunk_text
                    chunk_count += 1
                    
                    if self._is_sentence_complete(current_sentence):
                        sentence = current_sentence.strip()
                        if len(sentence) >= Config.MIN_SENTENCE_LENGTH:
                            sentence_count += 1
                            chunk_time = (current_time - start_time) * 1000
                            logger.info(f"ðŸ“¦ [STREAM-{request_id}] ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ #{sentence_count} Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ Ñ‡ÐµÑ€ÐµÐ· {chunk_time:.0f}Ð¼Ñ: '{sentence[:50]}...' (Ð´Ð»Ð¸Ð½Ð°: {len(sentence)})")
                            sentence_callback(sentence)
                        current_sentence = ""
            
            if current_sentence.strip():
                sentence = current_sentence.strip()
                if len(sentence) >= Config.MIN_SENTENCE_LENGTH:
                    sentence_count += 1
                    logger.info(f"ðŸ“¦ [STREAM-{request_id}] Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ #{sentence_count}: '{sentence[:50]}...' (Ð´Ð»Ð¸Ð½Ð°: {len(sentence)})")
                    sentence_callback(sentence)
                elif sentence:
                    sentence_count += 1
                    logger.info(f"ðŸ“¦ [STREAM-{request_id}] ÐšÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ #{sentence_count}: '{sentence}' (Ð´Ð»Ð¸Ð½Ð°: {len(sentence)})")
                    sentence_callback(sentence)
            
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            
            logger.info(f"ðŸ [STREAM-{request_id}] ÐŸÐ¾Ñ‚Ð¾Ðº Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ Ð·Ð° {total_time:.0f}Ð¼Ñ | "
                       f"Ð§Ð°Ð½ÐºÐ¾Ð²: {chunk_count} | ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹: {sentence_count} | "
                       f"Ð¡Ð¸Ð¼Ð²Ð¾Ð»Ð¾Ð²: {len(full_response)}")
                    
            return full_response.strip()
            
        except Exception as e:
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            logger.error(f"âŒ [STREAM-{request_id}] ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ñ‚Ð¾ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· {total_time:.0f}Ð¼Ñ: {e}")
            raise Exception(f"OpenAI Streaming Error: {e}")
    
    def get_response_stream_with_timeout(self, messages: List[Dict[str, str]], 
                                       sentence_callback: Callable[[str], None]) -> str:
        """
        ÐŸÐ¾Ñ‚Ð¾ÐºÐ¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð¼ - ÐµÑÐ»Ð¸ Ð´Ð¾Ð»Ð³Ð¾ Ð½ÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ñ… Ñ‡Ð°Ð½ÐºÐ¾Ð², 
        Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ
        """
        request_id = int(time.time() * 1000000) % 1000000
        
        logger.info(f"â° [TIMEOUT-{request_id}] ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ñ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð¼ Ðº OpenAI")
        start_time = time.time()
        first_chunk_time = None
        chunk_count = 0
        timeout_triggers = 0
        
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                reasoning_effort="minimal",
                stream=True
            )
            
            full_response = ""
            current_sentence = ""
            last_chunk_time = time.time()
            sentence_count = 0
            
            def timeout_sender():
                nonlocal current_sentence, timeout_triggers
                while True:
                    time.sleep(0.1)
                    current_time = time.time()
                    if current_sentence and current_time - last_chunk_time > Config.MAX_CHUNK_WAIT_TIME:
                        timeout_triggers += 1
                        wait_time = (current_time - last_chunk_time) * 1000
                        sentence = current_sentence.strip()
                        if sentence:
                            logger.info(f"â±ï¸ [TIMEOUT-{request_id}] Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ #{timeout_triggers} Ñ‡ÐµÑ€ÐµÐ· {wait_time:.0f}Ð¼Ñ: '{sentence[:50]}...'")
                            sentence_callback(sentence)
                        current_sentence = ""
                        break
            
            timeout_thread = None
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    current_time = time.time()
                    
                    if first_chunk_time is None:
                        first_chunk_time = current_time
                        time_to_first_chunk = (first_chunk_time - start_time) * 1000
                        logger.info(f"âš¡ [TIMEOUT-{request_id}] ÐŸÐµÑ€Ð²Ñ‹Ð¹ Ñ‡Ð°Ð½Ðº Ñ‡ÐµÑ€ÐµÐ· {time_to_first_chunk:.0f}Ð¼Ñ")
                    
                    chunk_text = chunk.choices[0].delta.content
                    full_response += chunk_text
                    current_sentence += chunk_text
                    last_chunk_time = current_time
                    chunk_count += 1
                    
                    if timeout_thread is None:
                        timeout_thread = threading.Thread(target=timeout_sender, daemon=True)
                        timeout_thread.start()
                    
                    if self._is_sentence_complete(current_sentence):
                        sentence = current_sentence.strip()
                        if len(sentence) >= Config.MIN_SENTENCE_LENGTH:
                            sentence_count += 1
                            chunk_time = (current_time - start_time) * 1000
                            logger.info(f"ðŸ“¦ [TIMEOUT-{request_id}] ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ #{sentence_count} Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ Ñ‡ÐµÑ€ÐµÐ· {chunk_time:.0f}Ð¼Ñ: '{sentence[:50]}...' (Ð´Ð»Ð¸Ð½Ð°: {len(sentence)})")
                            sentence_callback(sentence)
                        current_sentence = ""
                        if timeout_thread and timeout_thread.is_alive():
                            timeout_thread = threading.Thread(target=timeout_sender, daemon=True)
                            timeout_thread.start()
            
            if current_sentence.strip():
                sentence = current_sentence.strip()
                if sentence:
                    sentence_count += 1
                    logger.info(f"ðŸ“¦ [TIMEOUT-{request_id}] Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ #{sentence_count}: '{sentence[:50]}...'")
                    sentence_callback(sentence)
            
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            
            logger.info(f"ðŸ [TIMEOUT-{request_id}] ÐŸÐ¾Ñ‚Ð¾Ðº Ñ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ Ð·Ð° {total_time:.0f}Ð¼Ñ | "
                       f"Ð§Ð°Ð½ÐºÐ¾Ð²: {chunk_count} | ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹: {sentence_count} | "
                       f"Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð²: {timeout_triggers} | Ð¡Ð¸Ð¼Ð²Ð¾Ð»Ð¾Ð²: {len(full_response)}")
                    
            return full_response.strip()
            
        except Exception as e:
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            logger.error(f"âŒ [TIMEOUT-{request_id}] ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ñ‚Ð¾ÐºÐ° Ñ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð¼ Ñ‡ÐµÑ€ÐµÐ· {total_time:.0f}Ð¼Ñ: {e}")
            raise Exception(f"OpenAI Streaming with Timeout Error: {e}")
    
    def _is_sentence_complete(self, text: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ, Ð·Ð°ÐºÐ¾Ð½Ñ‡ÐµÐ½Ð¾ Ð»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ"""
        text = text.strip()
        if not text:
            return False
            
        for ending in Config.SENTENCE_ENDINGS:
            if text.endswith(ending):
                return True
                
        return False