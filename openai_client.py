import openai
import time
import threading
import logging
from datetime import datetime
from typing import List, Dict, Callable, Generator
from config import Config

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s.%(msecs)03d [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class OpenAIClient:
    def __init__(self):
        self.client = openai.OpenAI(api_key=Config.OPENAI_API_KEY)
        self.model = Config.OPENAI_MODEL
        
    def get_response_sync(self, messages: List[Dict[str, str]]) -> str:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å - –ø–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç —Å—Ä–∞–∑—É"""
        request_id = int(time.time() * 1000000) % 1000000  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∑–∞–ø—Ä–æ—Å–∞
        
        print(f"üöÄ [REQ-{request_id}] –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI")
        start_time = time.time()
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                reasoning_effort="minimal"
            )
            
            end_time = time.time()
            response_time = (end_time - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            content = response.choices[0].message.content.strip()
            
            print(f"‚úÖ [REQ-{request_id}] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –∑–∞ {response_time:.0f}–º—Å (–¥–ª–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
            return content
            
        except Exception as e:
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            logger.error(f"‚ùå [REQ-{request_id}] –û—à–∏–±–∫–∞ —á–µ—Ä–µ–∑ {response_time:.0f}–º—Å: {e}")
            raise Exception(f"OpenAI API Error: {e}")
    
    def get_response_stream(self, messages: List[Dict[str, str]], 
                          sentence_callback: Callable[[str], None]) -> str:
        """
        –ü–æ—Ç–æ–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å - —Å–æ–±–∏—Ä–∞–µ–º —á–∞–Ω–∫–∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö —á–µ—Ä–µ–∑ callback
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
        """
        request_id = int(time.time() * 1000000) % 1000000
        
        logger.info(f"üåä [STREAM-{request_id}] –ù–∞—á–∞–ª–æ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI")
        start_time = time.time()
        first_chunk_time = None
        chunk_count = 0
        
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                reasoning_effort="minimal",
                stream=True
            )
            
            full_response = ""
            current_sentence = ""
            sentence_count = 0
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    current_time = time.time()
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π —á–∞–Ω–∫
                    if first_chunk_time is None:
                        first_chunk_time = current_time
                        time_to_first_chunk = (first_chunk_time - start_time) * 1000
                        logger.info(f"‚ö° [STREAM-{request_id}] –ü–µ—Ä–≤—ã–π —á–∞–Ω–∫ —á–µ—Ä–µ–∑ {time_to_first_chunk:.0f}–º—Å")
                    
                    chunk_text = chunk.choices[0].delta.content
                    full_response += chunk_text
                    current_sentence += chunk_text
                    chunk_count += 1
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                    if self._is_sentence_complete(current_sentence):
                        sentence = current_sentence.strip()
                        if len(sentence) >= Config.MIN_SENTENCE_LENGTH:
                            sentence_count += 1
                            chunk_time = (current_time - start_time) * 1000
                            logger.info(f"üì¶ [STREAM-{request_id}] –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #{sentence_count} –≥–æ—Ç–æ–≤–æ —á–µ—Ä–µ–∑ {chunk_time:.0f}–º—Å: '{sentence[:50]}...' (–¥–ª–∏–Ω–∞: {len(sentence)})")
                            sentence_callback(sentence)
                        current_sentence = ""
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å
            if current_sentence.strip():
                sentence = current_sentence.strip()
                if len(sentence) >= Config.MIN_SENTENCE_LENGTH:
                    sentence_count += 1
                    logger.info(f"üì¶ [STREAM-{request_id}] –§–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #{sentence_count}: '{sentence[:50]}...' (–¥–ª–∏–Ω–∞: {len(sentence)})")
                    sentence_callback(sentence)
                elif sentence:  # –î–∞–∂–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Å—Ç–∞—Ç–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ü–µ
                    sentence_count += 1
                    logger.info(f"üì¶ [STREAM-{request_id}] –ö–æ—Ä–æ—Ç–∫–∏–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç #{sentence_count}: '{sentence}' (–¥–ª–∏–Ω–∞: {len(sentence)})")
                    sentence_callback(sentence)
            
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            
            logger.info(f"üèÅ [STREAM-{request_id}] –ü–æ—Ç–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_time:.0f}–º—Å | "
                       f"–ß–∞–Ω–∫–æ–≤: {chunk_count} | –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {sentence_count} | "
                       f"–°–∏–º–≤–æ–ª–æ–≤: {len(full_response)}")
                    
            return full_response.strip()
            
        except Exception as e:
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            logger.error(f"‚ùå [STREAM-{request_id}] –û—à–∏–±–∫–∞ –ø–æ—Ç–æ–∫–∞ —á–µ—Ä–µ–∑ {total_time:.0f}–º—Å: {e}")
            raise Exception(f"OpenAI Streaming Error: {e}")
    
    def get_response_stream_with_timeout(self, messages: List[Dict[str, str]], 
                                       sentence_callback: Callable[[str], None]) -> str:
        """
        –ü–æ—Ç–æ–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å —Ç–∞–π–º–∞—É—Ç–æ–º - –µ—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ—Ç –Ω–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤, 
        –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        """
        request_id = int(time.time() * 1000000) % 1000000
        
        logger.info(f"‚è∞ [TIMEOUT-{request_id}] –ù–∞—á–∞–ª–æ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å —Ç–∞–π–º–∞—É—Ç–æ–º –∫ OpenAI")
        start_time = time.time()
        first_chunk_time = None
        chunk_count = 0
        timeout_triggers = 0
        
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                reasoning_effort="minimal",
                stream=True
            )
            
            full_response = ""
            current_sentence = ""
            last_chunk_time = time.time()
            sentence_count = 0
            
            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Ç–∞–π–º–∞—É—Ç—É
            def timeout_sender():
                nonlocal current_sentence, timeout_triggers
                while True:
                    time.sleep(0.1)
                    current_time = time.time()
                    if current_sentence and current_time - last_chunk_time > Config.MAX_CHUNK_WAIT_TIME:
                        timeout_triggers += 1
                        wait_time = (current_time - last_chunk_time) * 1000
                        sentence = current_sentence.strip()
                        if sentence:
                            logger.info(f"‚è±Ô∏è [TIMEOUT-{request_id}] –¢–∞–π–º–∞—É—Ç #{timeout_triggers} —á–µ—Ä–µ–∑ {wait_time:.0f}–º—Å: '{sentence[:50]}...'")
                            sentence_callback(sentence)
                        current_sentence = ""
                        break
            
            timeout_thread = None
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    current_time = time.time()
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π —á–∞–Ω–∫
                    if first_chunk_time is None:
                        first_chunk_time = current_time
                        time_to_first_chunk = (first_chunk_time - start_time) * 1000
                        logger.info(f"‚ö° [TIMEOUT-{request_id}] –ü–µ—Ä–≤—ã–π —á–∞–Ω–∫ —á–µ—Ä–µ–∑ {time_to_first_chunk:.0f}–º—Å")
                    
                    chunk_text = chunk.choices[0].delta.content
                    full_response += chunk_text
                    current_sentence += chunk_text
                    last_chunk_time = current_time
                    chunk_count += 1
                    
                    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞
                    if timeout_thread is None:
                        timeout_thread = threading.Thread(target=timeout_sender, daemon=True)
                        timeout_thread.start()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                    if self._is_sentence_complete(current_sentence):
                        sentence = current_sentence.strip()
                        if len(sentence) >= Config.MIN_SENTENCE_LENGTH:
                            sentence_count += 1
                            chunk_time = (current_time - start_time) * 1000
                            logger.info(f"üì¶ [TIMEOUT-{request_id}] –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #{sentence_count} –≥–æ—Ç–æ–≤–æ —á–µ—Ä–µ–∑ {chunk_time:.0f}–º—Å: '{sentence[:50]}...' (–¥–ª–∏–Ω–∞: {len(sentence)})")
                            sentence_callback(sentence)
                        current_sentence = ""
                        # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä
                        if timeout_thread and timeout_thread.is_alive():
                            timeout_thread = threading.Thread(target=timeout_sender, daemon=True)
                            timeout_thread.start()
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
            if current_sentence.strip():
                sentence = current_sentence.strip()
                if sentence:
                    sentence_count += 1
                    logger.info(f"üì¶ [TIMEOUT-{request_id}] –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç #{sentence_count}: '{sentence[:50]}...'")
                    sentence_callback(sentence)
            
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            
            logger.info(f"üèÅ [TIMEOUT-{request_id}] –ü–æ—Ç–æ–∫ —Å —Ç–∞–π–º–∞—É—Ç–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_time:.0f}–º—Å | "
                       f"–ß–∞–Ω–∫–æ–≤: {chunk_count} | –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {sentence_count} | "
                       f"–¢–∞–π–º–∞—É—Ç–æ–≤: {timeout_triggers} | –°–∏–º–≤–æ–ª–æ–≤: {len(full_response)}")
                    
            return full_response.strip()
            
        except Exception as e:
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            logger.error(f"‚ùå [TIMEOUT-{request_id}] –û—à–∏–±–∫–∞ –ø–æ—Ç–æ–∫–∞ —Å —Ç–∞–π–º–∞—É—Ç–æ–º —á–µ—Ä–µ–∑ {total_time:.0f}–º—Å: {e}")
            raise Exception(f"OpenAI Streaming with Timeout Error: {e}")
    
    def _is_sentence_complete(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∑–∞–∫–æ–Ω—á–µ–Ω–æ –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"""
        text = text.strip()
        if not text:
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        for ending in Config.SENTENCE_ENDINGS:
            if text.endswith(ending):
                return True
                
        return False